{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .boolean { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .integer { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .string  { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datatable\n",
    "import itertools as it\n",
    "from owlready2 import *\n",
    "import math\n",
    "import joblib\n",
    "\n",
    "import pickle\n",
    "\n",
    "#para depurar los que letras que no están en el codigo ascii\n",
    "import unicodedata\n",
    "import functools\n",
    "import spacy\n",
    "import stanfordnlp\n",
    "#from spacy_stanfordnlp import StanfordNLPLanguage\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn import metrics\n",
    "#from wiki_dump_reader import Cleaner, iterate\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize,scale\n",
    "\n",
    "#from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "#from gensim.models.wrappers import LdaMallet\n",
    "#from gensim.corpora import Dictionary\n",
    "\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "#Operaciones con gráficos\n",
    "import scattertext as st\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool, LabelSet, ColumnDataSource, Range1d\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from multiprocessing import  Pool\n",
    "import math\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Config preparation\n",
    "\n",
    "with open('../config/config.json', 'r') as f:\n",
    "    config = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = config.get('rawpath')+config.get('corpus')+'/'+'corpus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/raw/20newsgroup/corpus.csv'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = datatable.fread(path_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import time \n",
    "from spacy_langdetect import LanguageDetector\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clase_positiva = corpus[datatable.f.target==1,:]\n",
    "clase_positiva.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_negativa = corpus[datatable.f.target==0,:]\n",
    "clase_negativa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_originales = corpus[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_originales.to_csv('corpus_df/indices_originales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_seleccionadas = random.sample(range(1,clase_positiva.shape[0]),300000)\n",
    "filas_totales = range(1,clase_positiva.shape[0])\n",
    "filas_para_clase_negativa=set(filas_totales)-set(filas_seleccionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filas_para_clase_negativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = corpus.to_pandas()['text']\n",
    "#y = corpus.to_pandas()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#        X, y,stratify=y, test_size=0.4)\n",
    "\n",
    "#X_test, X_val, y_test, y_val = train_test_split(\n",
    "#        X_test, y_test, stratify=y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_final = clase_positiva[filas,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_enneg = clase_positiva[list(filas_para_clase_negativa),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_enneg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_enneg.rbind(clase_negativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_enneg['target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus=clase_positiva.rbind(clase_positiva_enneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva.to_csv('corpus_df/corpus_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = clase_positiva[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.to_csv('corpus_df/indices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = datatable.fread('corpus_df/corpus_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = corpus['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_filter(token):\n",
    "    return not (token.is_punct | token.is_space | token.is_stop)\n",
    "filtered_tokens = []\n",
    "i = time.time()\n",
    "cont = 0\n",
    "for doc in nlp.pipe(docs,disable=[\"parser\",\"tagger\"]):\n",
    "    tokens = \" \".join(token.lemma_ for token in doc if token_filter(token))\n",
    "    filtered_tokens.append(tokens)\n",
    "f=time.time()\n",
    "elapsed = f - i\n",
    "\n",
    "print ('han pasado {0} s'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['normalizado'] =filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt = datatable.Frame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt['long']=corpusdt[:, datatable.f.normalizado.len()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpusdt[datatable.f.long<=10, :]\n",
    "del corpusdt [:,datatable.f.text]\n",
    "del corpusdt [:,datatable.f.long]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt = corpusdt.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = corpusdt['normalizado'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = []\n",
    "i = time.time()\n",
    "cont = 0\n",
    "for doc in nlp.pipe(textos,disable=[\"parser\",\"tagger\"]):\n",
    "    langs.append(doc.lang_)\n",
    "f = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = f - i\n",
    "corpusdt['lang']=langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt2 = datatable.Frame(corpusdt)\n",
    "corpusdt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpusdt2[datatable.f.lang!='en',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt2.to_csv('corpus_df/normalizado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de corpuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 50000 documentos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_original = pd.read_csv('corpus_df/indices_originales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_original['target'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = datatable.fread('corpus_df/normalizado.csv')\n",
    "corpus = corpus.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['target']=corpus['target'].apply(lambda x: int(x==True) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['target'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.merge(indice_original,how='left',on='index',suffixes=['','_original'])\n",
    "corpus.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.loc[(corpus.target==0) &(corpus.target_original==1) & (corpus.index>500010),'target_original']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.target_original.sum() #breve dufeebcua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_original[indice_original.target==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv('corpus_tm/corpus_normalizado_t_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('corpus_tm/corpus_normalizado_t_original.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionamiento\n",
    "\n",
    "Ahora vamos a proceder a separar el corpus original en 3:\n",
    "+ 50.000 para topic modeling solo con clase positiva. En este caso solo guardaremos los índices\n",
    "+ 3 corpus de 50.000, 100.000 y 250.000 documentos mezclando clase positiva y negativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardo indices con corpus solo target positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "df_positivo = corpus.loc[(corpus.target_original==1) & (corpus.target==1),:]\n",
    "indices_positivo = df_positivo['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_smp = df_positivo.sample(n=50000).loc[:,'index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_smp.to_csv('corpus_tm/indices_positivos_50k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardo los indices negativos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negativo = corpus.loc[(corpus.target_original==0) & (corpus.target==0),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genero subconjuntos de 25 mil positivos y negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "indices_smp_pos0 = df_positivo.sample(n=25000).loc[:,'index']\n",
    "indices_smp_neg0 = df_negativo.sample(n=25000).loc[:,'index']\n",
    "indices0 = indices_smp_pos0 + indices_smp_neg0\n",
    "indices0.to_csv('corpus_tm/corpus1_50k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos subconjuntos de 50.000 positivo y negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "indices_smp_pos1 = df_positivo.sample(n=50000).loc[:,'index']\n",
    "indices_smp_neg1 = df_negativo.sample(n=50000).loc[:,'index']\n",
    "indices1 = indices_smp_pos1 + indices_smp_neg1\n",
    "indices1.to_csv('corpus_tm/corpus1_100k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos subconjuntos de 125.000 positivo y negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "indices_smp_pos1 = df_positivo.sample(n=125000).loc[:,'index']\n",
    "indices_smp_neg1 = df_negativo.sample(n=125000).loc[:,'index']\n",
    "indices1 = indices_smp_pos1 + indices_smp_neg1\n",
    "indices1.to_csv('corpus_tm/corpus1_250k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clase_positiva = corpus[datatable.f.target==1,:]\n",
    "clase_positiva.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_negativa = corpus[datatable.f.target==0,:]\n",
    "clase_negativa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_originales = corpus[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_originales.to_csv('corpus_df/indices_originales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filas_seleccionadas = random.sample(range(1,clase_positiva.shape[0]),300000)\n",
    "filas_totales = range(1,clase_positiva.shape[0])\n",
    "filas_para_clase_negativa=set(filas_totales)-set(filas_seleccionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filas_para_clase_negativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = corpus.to_pandas()['text']\n",
    "#y = corpus.to_pandas()['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#        X, y,stratify=y, test_size=0.4)\n",
    "\n",
    "#X_test, X_val, y_test, y_val = train_test_split(\n",
    "#        X_test, y_test, stratify=y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_final = clase_positiva[filas,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_enneg = clase_positiva[list(filas_para_clase_negativa),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_enneg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_enneg.rbind(clase_negativa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva_enneg['target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus=clase_positiva.rbind(clase_positiva_enneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_positiva.to_csv('corpus_df/corpus_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = clase_positiva[:,1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.to_csv('corpus_df/indices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = datatable.fread('corpus_df/corpus_procesado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = corpus['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_filter(token):\n",
    "    return not (token.is_punct | token.is_space | token.is_stop)\n",
    "filtered_tokens = []\n",
    "i = time.time()\n",
    "cont = 0\n",
    "for doc in nlp.pipe(docs,disable=[\"parser\",\"tagger\"]):\n",
    "    tokens = \" \".join(token.lemma_ for token in doc if token_filter(token))\n",
    "    filtered_tokens.append(tokens)\n",
    "f=time.time()\n",
    "elapsed = f - i\n",
    "\n",
    "print ('han pasado {0} s'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['normalizado'] =filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt = datatable.Frame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt['long']=corpusdt[:, datatable.f.normalizado.len()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpusdt[datatable.f.long<=10, :]\n",
    "del corpusdt [:,datatable.f.text]\n",
    "del corpusdt [:,datatable.f.long]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt = corpusdt.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = corpusdt['normalizado'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = []\n",
    "i = time.time()\n",
    "cont = 0\n",
    "for doc in nlp.pipe(textos,disable=[\"parser\",\"tagger\"]):\n",
    "    langs.append(doc.lang_)\n",
    "f = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = f - i\n",
    "corpusdt['lang']=langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt2 = datatable.Frame(corpusdt)\n",
    "corpusdt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpusdt2[datatable.f.lang!='en',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusdt2.to_csv('corpus_df/normalizado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de corpuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 50000 documentos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_original = pd.read_csv('corpus_df/indices_originales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_original['target'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = datatable.fread('corpus_df/normalizado.csv')\n",
    "corpus = corpus.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['target']=corpus['target'].apply(lambda x: int(x==True) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['target'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus.merge(indice_original,how='left',on='index',suffixes=['','_original'])\n",
    "corpus.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.loc[(corpus.target==0) &(corpus.target_original==1) & (corpus.index>500010),'target_original']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.target_original.sum() #breve dufeebcua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_original[indice_original.target==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv('corpus_tm/corpus_normalizado_t_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('corpus_tm/corpus_normalizado_t_original.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particionamiento\n",
    "\n",
    "Ahora vamos a proceder a separar el corpus original en 3:\n",
    "+ 50.000 para topic modeling solo con clase positiva. En este caso solo guardaremos los índices\n",
    "+ 3 corpus de 50.000, 100.000 y 250.000 documentos mezclando clase positiva y negativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardo indices con corpus solo target positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "df_positivo = corpus.loc[(corpus.target_original==1) & (corpus.target==1),:]\n",
    "indices_positivo = df_positivo['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_smp = df_positivo.sample(n=50000).loc[:,'index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_smp.to_csv('corpus_tm/indices_positivos_50k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardo los indices negativos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negativo = corpus.loc[(corpus.target_original==0) & (corpus.target==0),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genero subconjuntos de 25 mil positivos y negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "indices_smp_pos0 = df_positivo.sample(n=25000).loc[:,'index']\n",
    "indices_smp_neg0 = df_negativo.sample(n=25000).loc[:,'index']\n",
    "indices0 = indices_smp_pos0 + indices_smp_neg0\n",
    "indices0.to_csv('corpus_tm/corpus1_50k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos subconjuntos de 50.000 positivo y negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "indices_smp_pos1 = df_positivo.sample(n=50000).loc[:,'index']\n",
    "indices_smp_neg1 = df_negativo.sample(n=50000).loc[:,'index']\n",
    "indices1 = indices_smp_pos1 + indices_smp_neg1\n",
    "indices1.to_csv('corpus_tm/corpus1_100k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generamos subconjuntos de 125.000 positivo y negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "indices_smp_pos1 = df_positivo.sample(n=125000).loc[:,'index']\n",
    "indices_smp_neg1 = df_negativo.sample(n=125000).loc[:,'index']\n",
    "indices1 = indices_smp_pos1 + indices_smp_neg1\n",
    "indices1.to_csv('corpus_tm/corpus1_250k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 Newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset=\"all\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\\nSubject: Pens fans reactions\\nOrganization: Post Office, Carnegie Mellon, Pittsburgh, PA\\nLines: 12\\nNNTP-Posting-Host: po4.andrew.cmu.edu\\n\\n\\n\\nI am sure some bashers of Pens fans are pretty confused about the lack\\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\\nI am  bit puzzled too and a bit relieved. However, I am going to put an end\\nto non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\\nare killing those Devils worse than I thought. Jagr just showed you why\\nhe is much better than his regular season stats. He is also a lot\\nfo fun to watch in the playoffs. Bowman should let JAgr have a lot of\\nfun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\\nregular season game.          PENS RULE!!!\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(text=data[\"data\"]).assign(target=data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.sys.ibm.pc.hardware'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target_names'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: Mamatha Devineni Ratnam &lt;mr47+@andrew.cm...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: mblawson@midway.ecn.uoknor.edu (Matthew ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: Alexander Samuel McDiarmid &lt;am2o+@andrew...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>From: rdell@cbnewsf.cb.att.com (richard.b.dell...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>From: chriss@netcom.com (Chris Silvester)\\nSub...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      From: Mamatha Devineni Ratnam <mr47+@andrew.cm...      10\n",
       "1      From: mblawson@midway.ecn.uoknor.edu (Matthew ...       3\n",
       "2      From: hilmi-er@dsv.su.se (Hilmi Eren)\\nSubject...      17\n",
       "3      From: guyd@austin.ibm.com (Guy Dawson)\\nSubjec...       3\n",
       "4      From: Alexander Samuel McDiarmid <am2o+@andrew...       4\n",
       "...                                                  ...     ...\n",
       "18841  From: jim.zisfein@factory.com (Jim Zisfein) \\n...      13\n",
       "18842  From: rdell@cbnewsf.cb.att.com (richard.b.dell...      12\n",
       "18843  From: westes@netcom.com (Will Estes)\\nSubject:...       3\n",
       "18844  From: steve@hcrlgw (Steven Collins)\\nSubject: ...       1\n",
       "18845  From: chriss@netcom.com (Chris Silvester)\\nSub...       7\n",
       "\n",
       "[18846 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text=df.text.replace(to_replace='From:(.*\\n)',value='',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.replace(to_replace='lines:(.*\\n)',value=' ',regex=True)\n",
    "df.text =df.text.replace(to_replace='Subject:(.*\\n)',value='',regex=True)\n",
    "df.text =df.text.replace(to_replace='Re(.*\\n)',value='',regex=True)\n",
    "\n",
    "df.text =df.text.replace(to_replace='[!\"#$%&\\'()*+,/:;<=>?@[\\\\]^_`{|}~]',value=' ',regex=True) #remove punctuation except\n",
    "df.text =df.text.replace(to_replace='-',value=' ',regex=True)\n",
    "df.text =df.text.replace(to_replace='\\s+',value=' ',regex=True)    #remove new line\n",
    "df.text =df.text.replace(to_replace='  ',value='',regex=True)                #remove double white space\n",
    "df.text = df.text.replace(to_replace='Subject ',value=' ',regex=True)\n",
    "\n",
    "df.text =df.text.apply(lambda x:x.strip())  # Ltrim and Rtrim of whitespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organization Post Office Carnegie Mellon Pitts...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summary Seek recommendations for VLB video car...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lines 95 Nntp Posting Host viktoria.dsv.su.se ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Originator guyd pal500.austin.ibm.com Organiza...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organization Sophomore Mechanical Engineering ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Organization Post Office Carnegie Mellon Pitts...      10\n",
       "1  Summary Seek recommendations for VLB video car...       3\n",
       "2  Lines 95 Nntp Posting Host viktoria.dsv.su.se ...      17\n",
       "3  Originator guyd pal500.austin.ibm.com Organiza...       3\n",
       "4  Organization Sophomore Mechanical Engineering ...       4"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-012ab3a6b187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emails(text):\n",
    "    regex =  r'\\S*@\\S*\\s?'\n",
    "    return re.sub(regex, '', text )\n",
    "\n",
    "def remove_newlinechars(text):\n",
    "    '''\n",
    "    Substitute any newline chars with a whitespach\n",
    "    \n",
    "    The `regex` can be tried at: https://regex101.com/r/2fImPz/1/\n",
    "    '''\n",
    "    regex = r'\\s+'\n",
    "    return re.sub(regex, ' ', text)\n",
    "\n",
    "def token_filter(token):\n",
    "    return not (token.is_punct | token.is_space | token.is_stop)\n",
    "filtered_tokens = []\n",
    "i = time.time()\n",
    "cont = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "dask_dataframe = ddf.from_pandas(df, npartitions=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "def clean_text(df):\n",
    "    '''\n",
    "    Take in a Dataframe, and process it\n",
    "    '''\n",
    "    df[\"cleaned_text\"] = df.text.map(lambda text:text.lower()).map(remove_emails).map(remove_newlinechars)\n",
    "    \n",
    "    return df\n",
    "df = clean_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['cleaned_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to process without Dask 2128.312903881073\n"
     ]
    }
   ],
   "source": [
    "filtered_tokens = []\n",
    "for doc in nlp.pipe(docs,disable=[\"parser\",\"tagger\"],n_threads=10):\n",
    "    tokens = \" \".join(token.lemma_ for token in doc if token_filter(token))\n",
    "    filtered_tokens.append(tokens)\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Time to process without Dask {}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "corpus = copy.deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_tokens) == df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['cleaned_text']=filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv(config.get('interimpath')+'/20newsgroup/corpus_normalizado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(config.get('interimpath')+'/20newsgroup/corpus_normalizado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('../data/interim/20newsgroup/corpus_normalizado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>973</td>\n",
       "      <td>973</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>982</td>\n",
       "      <td>982</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>988</td>\n",
       "      <td>988</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>994</td>\n",
       "      <td>994</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>991</td>\n",
       "      <td>991</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>984</td>\n",
       "      <td>984</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>987</td>\n",
       "      <td>987</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>910</td>\n",
       "      <td>910</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>775</td>\n",
       "      <td>775</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>628</td>\n",
       "      <td>628</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  text  cleaned_text\n",
       "target                                \n",
       "0              799   799           799\n",
       "1              973   973           973\n",
       "2              985   985           985\n",
       "3              982   982           982\n",
       "4              963   963           963\n",
       "5              988   988           988\n",
       "6              975   975           975\n",
       "7              990   990           990\n",
       "8              996   996           996\n",
       "9              994   994           994\n",
       "10             999   999           999\n",
       "11             991   991           991\n",
       "12             984   984           984\n",
       "13             990   990           990\n",
       "14             987   987           987\n",
       "15             997   997           997\n",
       "16             910   910           910\n",
       "17             940   940           940\n",
       "18             775   775           775\n",
       "19             628   628           628"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby(by='target').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['Target']=corpus.target.apply(lambda x:  x==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus ['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv('../data/interim/20newsgroup/corpus_normalizado.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('../data/interim/20newsgroup/corpus_normalizado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Organization Post Office Carnegie Mellon Pitts...</td>\n",
       "      <td>10</td>\n",
       "      <td>organization post office carnegie mellon pitts...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summary Seek recommendations for VLB video car...</td>\n",
       "      <td>3</td>\n",
       "      <td>summary seek recommendation vlb video card nnt...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lines 95 Nntp Posting Host viktoria.dsv.su.se ...</td>\n",
       "      <td>17</td>\n",
       "      <td>line 95 nntp post host viktoria.dsv.su.se orga...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Originator guyd pal500.austin.ibm.com Organiza...</td>\n",
       "      <td>3</td>\n",
       "      <td>originator guyd pal500.austin.ibm.com organiza...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Organization Sophomore Mechanical Engineering ...</td>\n",
       "      <td>4</td>\n",
       "      <td>organization sophomore mechanical engineer car...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Organization Post Office Carnegie Mellon Pitts...      10   \n",
       "1  Summary Seek recommendations for VLB video car...       3   \n",
       "2  Lines 95 Nntp Posting Host viktoria.dsv.su.se ...      17   \n",
       "3  Originator guyd pal500.austin.ibm.com Organiza...       3   \n",
       "4  Organization Sophomore Mechanical Engineering ...       4   \n",
       "\n",
       "                                        cleaned_text  Target  \n",
       "0  organization post office carnegie mellon pitts...   False  \n",
       "1  summary seek recommendation vlb video card nnt...    True  \n",
       "2  line 95 nntp post host viktoria.dsv.su.se orga...   False  \n",
       "3  originator guyd pal500.austin.ibm.com organiza...    True  \n",
       "4  organization sophomore mechanical engineer car...   False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REUTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   categories  file_count\n",
      "21       earn        3964\n",
      "0         acq        2369\n",
      "46   money-fx         717\n",
      "26      grain         582\n",
      "17      crude         578\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "file_count = []\n",
    "\n",
    "# count each tag's number of documents\n",
    "for i in reuters.categories():\n",
    "    \"\"\"print(\"$ There are {} documents included in topic \\\"{}\\\"\"\n",
    "          .format(len(reuters.fileids(i)), i))\"\"\"\n",
    "    file_count.append(len(reuters.fileids(i)))\n",
    "    categories.append(i)\n",
    "\n",
    "# create a dataframe out of the counts\n",
    "df = pd.DataFrame(\n",
    "    {'categories': categories, \"file_count\": file_count}) \\\n",
    "    .sort_values('file_count', ascending=False)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipFilePathPointer('/home/rdelaguila/nltk_data/corpora/reuters.zip', 'reuters/test/14828')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.abspath(reuters.fileids()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = reuters.fileids()\n",
    "\n",
    "# Initialize empty lists to store categories and raw text\n",
    "categories = []\n",
    "text = []\n",
    "\n",
    "# Loop through each file id and collect each files categories and raw text\n",
    "for file in fileids:\n",
    "    categories.append(reuters.categories(file))\n",
    "    text.append(reuters.raw(file))\n",
    "\n",
    "# Combine lists into pandas dataframe. reutersDf is the final dataframe. \n",
    "reutersDf = pd.DataFrame({'ids':fileids, 'categories':categories, 'text':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "reutersDf.to_csv(config.get('rawpath')+config.get('corpus')+'/corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>[trade]</td>\n",
       "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/14828</td>\n",
       "      <td>[grain]</td>\n",
       "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/14829</td>\n",
       "      <td>[crude, nat-gas]</td>\n",
       "      <td>JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/14832</td>\n",
       "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
       "      <td>THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/14833</td>\n",
       "      <td>[palm-oil, veg-oil]</td>\n",
       "      <td>INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids                                      categories  \\\n",
       "0  test/14826                                         [trade]   \n",
       "1  test/14828                                         [grain]   \n",
       "2  test/14829                                [crude, nat-gas]   \n",
       "3  test/14832  [corn, grain, rice, rubber, sugar, tin, trade]   \n",
       "4  test/14833                             [palm-oil, veg-oil]   \n",
       "\n",
       "                                                text  \n",
       "0  ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...  \n",
       "1  CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...  \n",
       "2  JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...  \n",
       "3  THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...  \n",
       "4  INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reutersDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as ddf\n",
    "dask_dataframe = ddf.from_pandas(reutersDf, npartitions=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "def clean_text(df):\n",
    "    '''\n",
    "    Take in a Dataframe, and process it\n",
    "    '''\n",
    "    df[\"cleaned_text\"] = df.text.map(lambda text:text.lower()).map(remove_emails).map(remove_newlinechars)\n",
    "    \n",
    "    return df\n",
    "df = clean_text(reutersDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>[trade]</td>\n",
       "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...</td>\n",
       "      <td>asian exporters fear damage from u.s.-japan ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/14828</td>\n",
       "      <td>[grain]</td>\n",
       "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
       "      <td>china daily says vermin eat 7-12 pct grain sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/14829</td>\n",
       "      <td>[crude, nat-gas]</td>\n",
       "      <td>JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...</td>\n",
       "      <td>japan to revise long-term energy demand downwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/14832</td>\n",
       "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
       "      <td>THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...</td>\n",
       "      <td>thai trade deficit widens in first quarter tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/14833</td>\n",
       "      <td>[palm-oil, veg-oil]</td>\n",
       "      <td>INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...</td>\n",
       "      <td>indonesia sees cpo price rising sharply indone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10783</th>\n",
       "      <td>training/999</td>\n",
       "      <td>[interest, money-fx]</td>\n",
       "      <td>U.K. MONEY MARKET SHORTAGE FORECAST REVISED DO...</td>\n",
       "      <td>u.k. money market shortage forecast revised do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>training/9992</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>KNIGHT-RIDDER INC &amp;lt;KRN&gt; SETS QUARTERLY\\n  Q...</td>\n",
       "      <td>knight-ridder inc &amp;lt;krn&gt; sets quarterly qtly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10785</th>\n",
       "      <td>training/9993</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>TECHNITROL INC &amp;lt;TNL&gt; SETS QUARTERLY\\n  Qtly...</td>\n",
       "      <td>technitrol inc &amp;lt;tnl&gt; sets quarterly qtly di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>training/9994</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>NATIONWIDE CELLULAR SERVICE INC &amp;lt;NCEL&gt; 4TH ...</td>\n",
       "      <td>nationwide cellular service inc &amp;lt;ncel&gt; 4th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10787</th>\n",
       "      <td>training/9995</td>\n",
       "      <td>[earn]</td>\n",
       "      <td>&amp;lt;A.H.A. AUTOMOTIVE TECHNOLOGIES CORP&gt; YEAR ...</td>\n",
       "      <td>&amp;lt;a.h.a. automotive technologies corp&gt; year ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ids                                      categories  \\\n",
       "0         test/14826                                         [trade]   \n",
       "1         test/14828                                         [grain]   \n",
       "2         test/14829                                [crude, nat-gas]   \n",
       "3         test/14832  [corn, grain, rice, rubber, sugar, tin, trade]   \n",
       "4         test/14833                             [palm-oil, veg-oil]   \n",
       "...              ...                                             ...   \n",
       "10783   training/999                            [interest, money-fx]   \n",
       "10784  training/9992                                          [earn]   \n",
       "10785  training/9993                                          [earn]   \n",
       "10786  training/9994                                          [earn]   \n",
       "10787  training/9995                                          [earn]   \n",
       "\n",
       "                                                    text  \\\n",
       "0      ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...   \n",
       "1      CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...   \n",
       "2      JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...   \n",
       "3      THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...   \n",
       "4      INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...   \n",
       "...                                                  ...   \n",
       "10783  U.K. MONEY MARKET SHORTAGE FORECAST REVISED DO...   \n",
       "10784  KNIGHT-RIDDER INC &lt;KRN> SETS QUARTERLY\\n  Q...   \n",
       "10785  TECHNITROL INC &lt;TNL> SETS QUARTERLY\\n  Qtly...   \n",
       "10786  NATIONWIDE CELLULAR SERVICE INC &lt;NCEL> 4TH ...   \n",
       "10787  &lt;A.H.A. AUTOMOTIVE TECHNOLOGIES CORP> YEAR ...   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      asian exporters fear damage from u.s.-japan ri...  \n",
       "1      china daily says vermin eat 7-12 pct grain sto...  \n",
       "2      japan to revise long-term energy demand downwa...  \n",
       "3      thai trade deficit widens in first quarter tha...  \n",
       "4      indonesia sees cpo price rising sharply indone...  \n",
       "...                                                  ...  \n",
       "10783  u.k. money market shortage forecast revised do...  \n",
       "10784  knight-ridder inc &lt;krn> sets quarterly qtly...  \n",
       "10785  technitrol inc &lt;tnl> sets quarterly qtly di...  \n",
       "10786  nationwide cellular service inc &lt;ncel> 4th ...  \n",
       "10787  &lt;a.h.a. automotive technologies corp> year ...  \n",
       "\n",
       "[10788 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df['cleaned_text']\n",
    "corpus=copy.deepcopy(df)\n",
    "filtered_tokens=[]\n",
    "for doc in nlp.pipe(docs,disable=[\"parser\",\"tagger\"]):\n",
    "    tokens = \" \".join(token.lemma_ for token in doc if token_filter(token))\n",
    "    filtered_tokens.append(tokens)\n",
    "\n",
    "corpus['texto_normalizado']=filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>categories</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>texto_normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/14826</td>\n",
       "      <td>[trade]</td>\n",
       "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...</td>\n",
       "      <td>asian exporters fear damage from u.s.-japan ri...</td>\n",
       "      <td>asian exporter fear damage u.s.-japan rift mou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/14828</td>\n",
       "      <td>[grain]</td>\n",
       "      <td>CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...</td>\n",
       "      <td>china daily says vermin eat 7-12 pct grain sto...</td>\n",
       "      <td>china daily say vermin eat 7 12 pct grain stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/14829</td>\n",
       "      <td>[crude, nat-gas]</td>\n",
       "      <td>JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...</td>\n",
       "      <td>japan to revise long-term energy demand downwa...</td>\n",
       "      <td>japan revise long term energy demand downwards...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/14832</td>\n",
       "      <td>[corn, grain, rice, rubber, sugar, tin, trade]</td>\n",
       "      <td>THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...</td>\n",
       "      <td>thai trade deficit widens in first quarter tha...</td>\n",
       "      <td>thai trade deficit widen quarter thailand trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/14833</td>\n",
       "      <td>[palm-oil, veg-oil]</td>\n",
       "      <td>INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...</td>\n",
       "      <td>indonesia sees cpo price rising sharply indone...</td>\n",
       "      <td>indonesia see cpo price rise sharply indonesia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids                                      categories  \\\n",
       "0  test/14826                                         [trade]   \n",
       "1  test/14828                                         [grain]   \n",
       "2  test/14829                                [crude, nat-gas]   \n",
       "3  test/14832  [corn, grain, rice, rubber, sugar, tin, trade]   \n",
       "4  test/14833                             [palm-oil, veg-oil]   \n",
       "\n",
       "                                                text  \\\n",
       "0  ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RI...   \n",
       "1  CHINA DAILY SAYS VERMIN EAT 7-12 PCT GRAIN STO...   \n",
       "2  JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWA...   \n",
       "3  THAI TRADE DEFICIT WIDENS IN FIRST QUARTER\\n  ...   \n",
       "4  INDONESIA SEES CPO PRICE RISING SHARPLY\\n  Ind...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  asian exporters fear damage from u.s.-japan ri...   \n",
       "1  china daily says vermin eat 7-12 pct grain sto...   \n",
       "2  japan to revise long-term energy demand downwa...   \n",
       "3  thai trade deficit widens in first quarter tha...   \n",
       "4  indonesia sees cpo price rising sharply indone...   \n",
       "\n",
       "                                   texto_normalizado  \n",
       "0  asian exporter fear damage u.s.-japan rift mou...  \n",
       "1  china daily say vermin eat 7 12 pct grain stoc...  \n",
       "2  japan revise long term energy demand downwards...  \n",
       "3  thai trade deficit widen quarter thailand trad...  \n",
       "4  indonesia see cpo price rise sharply indonesia...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv(config.get('interimpath')+'/reuters/corpus_normalizado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are setting acq as positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv(config.get('interimpath')+'/reuters/corpus_normalizado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ids</th>\n",
       "      <th>categories</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>texto_normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test/14826</td>\n",
       "      <td>['trade']</td>\n",
       "      <td>asian exporters fear damage from u.s.-japan ri...</td>\n",
       "      <td>asian exporter fear damage u.s.-japan rift mou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test/14828</td>\n",
       "      <td>['grain']</td>\n",
       "      <td>china daily says vermin eat 7-12 pct grain sto...</td>\n",
       "      <td>china daily say vermin eat 7 12 pct grain stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test/14829</td>\n",
       "      <td>['crude', 'nat-gas']</td>\n",
       "      <td>japan to revise long-term energy demand downwa...</td>\n",
       "      <td>japan revise long term energy demand downwards...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test/14832</td>\n",
       "      <td>['corn', 'grain', 'rice', 'rubber', 'sugar', '...</td>\n",
       "      <td>thai trade deficit widens in first quarter tha...</td>\n",
       "      <td>thai trade deficit widen quarter thailand trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test/14833</td>\n",
       "      <td>['palm-oil', 'veg-oil']</td>\n",
       "      <td>indonesia sees cpo price rising sharply indone...</td>\n",
       "      <td>indonesia see cpo price rise sharply indonesia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         ids                                         categories  \\\n",
       "0           0  test/14826                                          ['trade']   \n",
       "1           1  test/14828                                          ['grain']   \n",
       "2           2  test/14829                               ['crude', 'nat-gas']   \n",
       "3           3  test/14832  ['corn', 'grain', 'rice', 'rubber', 'sugar', '...   \n",
       "4           4  test/14833                            ['palm-oil', 'veg-oil']   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  asian exporters fear damage from u.s.-japan ri...   \n",
       "1  china daily says vermin eat 7-12 pct grain sto...   \n",
       "2  japan to revise long-term energy demand downwa...   \n",
       "3  thai trade deficit widens in first quarter tha...   \n",
       "4  indonesia sees cpo price rising sharply indone...   \n",
       "\n",
       "                                   texto_normalizado  \n",
       "0  asian exporter fear damage u.s.-japan rift mou...  \n",
       "1  china daily say vermin eat 7 12 pct grain stoc...  \n",
       "2  japan revise long term energy demand downwards...  \n",
       "3  thai trade deficit widen quarter thailand trad...  \n",
       "4  indonesia see cpo price rise sharply indonesia...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                ['trade']\n",
       "1                                                ['grain']\n",
       "2                                     ['crude', 'nat-gas']\n",
       "3        ['corn', 'grain', 'rice', 'rubber', 'sugar', '...\n",
       "4                                  ['palm-oil', 'veg-oil']\n",
       "                               ...                        \n",
       "10783                             ['interest', 'money-fx']\n",
       "10784                                             ['earn']\n",
       "10785                                             ['earn']\n",
       "10786                                             ['earn']\n",
       "10787                                             ['earn']\n",
       "Name: categories, Length: 10788, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " corpus['categories'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['Target']=corpus.categories.apply(lambda x:  'acq' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2369"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.Target.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del corpus ['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv(config.get('interimpath')+'/reuters/corpus_normalizado.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
